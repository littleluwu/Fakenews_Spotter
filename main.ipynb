{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spotting Fake News with Python**\n",
    "\n",
    "This project aims to investigate the task of spotting fake news and apply classic and modern machine learning techniques to develop a model that can classify news as real or fake. It is part of an assignment for the course `486205 - APRENDIZADO DE MÁQUINA` at the **Federal University of São Carlos (UFSCar)**, lectured by the professor **Tiago A. Almeida**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Enviroment Setup and Loading Data**\n",
    "\n",
    "The first step in this problem is to import the tools we will need further in the project. To begin the setup, we imported **pandas** and **NumPy** to manipulate the data.\n",
    "\n",
    "News is written in a natural language that humans understand, so it is necessary to clean and prepare this data for machine processing. To satisfy our natural language processing needs throughout the project, we have decided to use the **NLTK** library. \n",
    "\n",
    "To improve our understanding of the task and the data we are working with, we have chosen **matplotlib** as our visualization library to clarify the extracted information from the processed news.\n",
    "\n",
    "Compiling all the decisions, we imported the following libraries for this project:\n",
    "\n",
    "- pandas\n",
    "- NumPy\n",
    "- NLTK\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using in this project was provided by the professor for use in the assignment. It compiles news automatically collected during 2019 and 2020 with no supervision. This indicates the possibility of data corruption or information loss during the collection phase. A given news presented in the dataset can be classified in a binary way:\n",
    "\n",
    "- **1** -> The news is trustworthy (Real).\n",
    "- **0** -> The news is not trustworthy (Possibly Fake).\n",
    "\n",
    "However, it wasn't possible to check if the information was reliable in a large amount of samples. Thus, these news articles do not exhibit any label attached to them. The data is organized by month and year in separate CSV files, which include a unique identification for each article, both the titles and contents and the binary label attached to them. To work with this data, we imported each file and compiled them in a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"news_data_01_Jan_2019.csv\",\n",
    "         \"news_data_02_Feb_2019.csv\",\n",
    "         \"news_data_03_Mar_2019.csv\",\n",
    "         \"news_data_04_Apr_2019.csv\",\n",
    "         \"news_data_05_May_2019.csv\",\n",
    "         \"news_data_06_Jun_2019.csv\",\n",
    "         \"news_data_07_Jul_2019.csv\",\n",
    "         \"news_data_08_Aug_2019.csv\",\n",
    "         \"news_data_09_Sep_2019.csv\",\n",
    "         \"news_data_10_Oct_2019.csv\",\n",
    "         \"news_data_11_Nov_2019.csv\",\n",
    "         \"news_data_12_Dec_2019.csv\",\n",
    "         \"news_data_13_Jan_2020.csv\",\n",
    "         \"news_data_14_Feb_2020.csv\",\n",
    "         \"news_data_15_Mar_2020.csv\",\n",
    "         \"news_data_16_Apr_2020.csv\",\n",
    "         \"news_data_17_May_2020.csv\",\n",
    "         \"news_data_18_Jun_2020.csv\",\n",
    "         \"news_data_19_Jul_2020.csv\",\n",
    "         \"news_data_20_Aug_2020.csv\",\n",
    "         \"news_data_21_Sep_2020.csv\",\n",
    "         \"news_data_22_Oct_2020.csv\",\n",
    "         \"news_data_23_Nov_2020.csv\",\n",
    "         \"news_data_24_Dec_2020.csv\",\n",
    "         ]\n",
    "\n",
    "data = pd.concat((pd.read_csv(\"./data/\"+f) for f in files), ignore_index=True)\n",
    "data.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Exploring the news and their content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Applying machine learning to detect fake news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Experiment Results and Comments**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
